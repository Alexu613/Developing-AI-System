{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing AI System\n",
    "\n",
    "### Chatbot\n",
    "\n",
    "A **chatbot** is a computer program that simulates human conversation, usually through text or voice. With **OpenAI**, a chatbot uses powerful language models like **GPT-4** to understand questions and generate smart, human-like answers.\n",
    "\n",
    "In simple terms:\n",
    "\n",
    "> A chatbot with OpenAI can chat, answer questions, summarize info, or help with tasks — almost like talking to a helpful assistant.\n",
    "\n",
    "It works by sending messages to the model (input) and receiving a response (output), often using the `chat.completions.create()` function from the OpenAI API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexBot is ready. Tape 'exit' to quit the conversation\n",
      "ChniniBot : Salut ! Comment puis-je vous aider aujourd'hui ?\n",
      "--------------------------------------------------\n",
      "Thanks for choosing AlexBot. See you soon !\n"
     ]
    }
   ],
   "source": [
    "#This version of chatbot can only be running through the console,\n",
    "#Check code app.py a version of this chatbot deployed on Streamlit Platform for a better experience\n",
    "#To run the chatbot --> Terminal : streamlit run app.py\n",
    "\n",
    "import os \n",
    "import openai\n",
    "from time import sleep\n",
    "from tqdm import tgrange, tqdm_notebook\n",
    "\n",
    "#Bloc\n",
    "MESSAGES = [{\"role\":\"system\", \"content\": \"You're a Chatbot, your name is AlexBot you've been created by Alexandre Ohayon, you can answer any customer's questions by summarizing your answer.\"}]\n",
    "#Dialog Box ask your question to the ChatBot:\n",
    "\n",
    "try:\n",
    "    print(\"AlexBot is ready. Tape 'exit' to quit the conversation\")\n",
    "\n",
    "    #Start a session:\n",
    "    while True:\n",
    "        #Enter your question:\n",
    "        USER_PROMPT = input(\"Enter your message here: \") #Use the dialog box\n",
    "        #Tape exist in lower character to quit the conversation with the Bot.\n",
    "        if USER_PROMPT.lower() == \"exit\": \n",
    "            print(\"Thanks for choosing AlexBot. See you soon !\") #Message from system\n",
    "            break #Session closed\n",
    "            \n",
    "        #If a conversation exists then add user question to the Bloc in line 7:\n",
    "        MESSAGES.append({\"role\":\"user\", \"content\": USER_PROMPT}) #Add the question into the list:\n",
    "        user_question = {\"role\":\"user\", \"content\": USER_PROMPT}\n",
    "        #print(f\"User_question : {USER_PROMPT}\")\n",
    "\n",
    "                \n",
    "        #Pass MESSAGES through the LLM to get response from the AI Agent:\n",
    "        client = openai.OpenAI(organization=None,\n",
    "                                project=None, \n",
    "                                timeout=60*5, #5 minutes and break after that\n",
    "                                max_retries=2,\n",
    "                                api_key=API_KEY)\n",
    "            \n",
    "        #Response from the Intelligent Agent:\n",
    "        # Add the appropriate parameters to the decorator\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=MESSAGES,\n",
    "            max_tokens=300,\n",
    "            temperature=0,\n",
    "            top_p=0.9,\n",
    "            stop=[\"\\n\"]\n",
    "        )\n",
    "\n",
    "        assistant_dict = {\"role\":\"assistant\", \"content\": response.choices[0].message.content}\n",
    "        print(f\"ChniniBot : {assistant_dict[\"content\"]}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        #Add the question into the list:\n",
    "        MESSAGES.append(assistant_dict)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error :\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get response in Json Format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"plats\": [\n",
      "    { \"nom\": \"Sushi\", \"pays\": \"Japon\" },\n",
      "    { \"nom\": \"Pizza\", \"pays\": \"Italie\" },\n",
      "    { \"nom\": \"Tacos\", \"pays\": \"Mexique\" },\n",
      "    { \"nom\": \"Croissant\", \"pays\": \"France\" },\n",
      "    { \"nom\": \"Paella\", \"pays\": \"Espagne\" },\n",
      "    { \"nom\": \"Curry\", \"pays\": \"Inde\" },\n",
      "    { \"nom\": \"Poutine\", \"pays\": \"Canada\" },\n",
      "    { \"nom\": \"Hamburger\", \"pays\": \"États-Unis\" },\n",
      "    { \"nom\": \"Falafel\", \"pays\": \"Moyen-Orient\" },\n",
      "    { \"nom\": \"Kimchi\", \"pays\": \"Corée du Sud\" }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Initialisation du client OpenAI avec la clé API (via variable d'environnement)\n",
    "client = openai.OpenAI(organization=None,\n",
    "                                project=None, \n",
    "                                timeout=60*5, #5 minutes and break after that\n",
    "                                max_retries=2,\n",
    "                                api_key=API_KEY) # Remplace si besoin\n",
    "\n",
    "def get_famous_dishes_by_country():\n",
    "    # Prompt demandé\n",
    "    prompt = (\n",
    "        \"Donne-moi une liste des 10 plats les plus connus dans le monde, \"\n",
    "        \"triée par pays, au format JSON. Pour chaque plat, indique le nom du plat et le pays d'origine. \"\n",
    "        \"Utilise ce format : \"\n",
    "        '{ \"plats\": [ { \"nom\": \"Sushi\", \"pays\": \"Japon\" }, ... ] }'\n",
    "    )\n",
    "\n",
    "    # Appel à l'API avec la méthode chat.completions.create\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # ou \"gpt-4\"\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Tu es un assistant culinaire qui fournit des réponses en JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=500,\n",
    "        response_format={\"type\":\"json_object\"} # Nécessite GPT-4-turbo ou GPT-4o\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    json_result = get_famous_dishes_by_country()\n",
    "    print(json_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
